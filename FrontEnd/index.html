<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Live Caption Overlay</title>
    <meta http-equiv="Content-Security-Policy" content="script-src 'self' 'unsafe-inline';" />
    
    <link rel="stylesheet" href="style.css"> 
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <div class="caption-container">
        <div id="caption-box" class="caption-box">
            <p id="caption-output">Pressione INICIAR para come√ßar a legendar...</p>
        </div>

        <div id="control-panel" class="control-panel hidden">
            <button id="startButton" class="control-button"><i class="fas fa-play"></i> INICIAR</button>
            
            <button id="pauseResumeButton" class="control-button" disabled>
                <i class="fas fa-pause"></i> PAUSAR
            </button>
            
            <button id="stopButton" class="control-button" disabled>
                <i class="fas fa-stop"></i> FINALIZAR
            </button>
            
            <button id="closeButton" class="control-button">
                <i class="fas fa-times"></i> FECHAR
            </button>
        </div>
    </div>
    <script>

        const { ipcRenderer } = require('electron');
        // *** IMPORTANTE: ENVOLVA TODO O SEU C√ìDIGO DENTRO DE DOMContentLoaded ***
        // Isso garante que o JS s√≥ tente buscar os elementos HTML AP√ìS eles existirem.
        document.addEventListener('DOMContentLoaded', () => {
            
            // Seu c√≥digo JavaScript come√ßa aqui (AGORA FUNCIONAR√Å):

            const { ipcRenderer } = require('electron');

            // As vari√°veis agora encontrar√£o os elementos no DOM
            const captionOutput = document.getElementById('caption-output');
            const startButton = document.getElementById('startButton');
            const pauseResumeButton = document.getElementById('pauseResumeButton');
            const stopButton = document.getElementById('stopButton');
            const controlPanel = document.getElementById('control-panel');
            const captionContainer = document.querySelector('.caption-container');
            
            // Vari√°veis de controle de √°udio
            let mediaRecorder;
            let audioStream;
            let audioChunks = [];
            let isListening = false;
            let isPaused = false;

            // --- Configura√ß√µes de Transcri√ß√£o (Para Python) ---
            const CHUNK_INTERVAL = 1500;
            const PYTHON_API_URL = 'http://127.0.0.1:5001/transcribe';
            // ----------------------------------------------------
            
            // --- FUN√á√ïES DE CONTROLE DE INTERATIVIDADE (ELECTRON) ---
            // ... (Seu c√≥digo de enableInteraction e disableInteraction) ...
            function enableInteraction() {
                ipcRenderer.send('set-ignore-mouse-events', false);
                controlPanel.classList.remove('hidden');
            }
            
            function disableInteraction() {
                ipcRenderer.send('set-ignore-mouse-events', true, { forward: true });
                controlPanel.classList.add('hidden');
            }


            // --- L√ìGICA DE √ÅUDIO E COMUNICA√á√ÉO COM PYTHON ---
            // ... (Seu c√≥digo de sendAudioChunk) ...
            // Convert a recorded Blob (any browser audio container) into WAV Blob
            async function blobToWav(blob) {
                const arrayBuffer = await blob.arrayBuffer();
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                try {
                    const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

                    function interleave(inputL, inputR) {
                        const length = inputL.length + inputR.length;
                        const result = new Float32Array(length);
                        let index = 0;
                        let inputIndex = 0;
                        while (index < length) {
                            result[index++] = inputL[inputIndex];
                            result[index++] = inputR[inputIndex];
                            inputIndex++;
                        }
                        return result;
                    }

                    function writeString(view, offset, string) {
                        for (let i = 0; i < string.length; i++) {
                            view.setUint8(offset + i, string.charCodeAt(i));
                        }
                    }

                    const numChannels = audioBuffer.numberOfChannels;
                    const sampleRate = audioBuffer.sampleRate;
                    let samples;

                    if (numChannels === 2) {
                        samples = interleave(audioBuffer.getChannelData(0), audioBuffer.getChannelData(1));
                    } else {
                        samples = audioBuffer.getChannelData(0);
                    }

                    const bytesPerSample = 2;
                    const blockAlign = numChannels * bytesPerSample;
                    const buffer = new ArrayBuffer(44 + samples.length * bytesPerSample);
                    const view = new DataView(buffer);

                    /* RIFF identifier */
                    writeString(view, 0, 'RIFF');
                    /* file length */
                    view.setUint32(4, 36 + samples.length * bytesPerSample, true);
                    /* RIFF type */
                    writeString(view, 8, 'WAVE');
                    /* format chunk identifier */
                    writeString(view, 12, 'fmt ');
                    /* format chunk length */
                    view.setUint32(16, 16, true);
                    /* sample format (raw) */
                    view.setUint16(20, 1, true);
                    /* channel count */
                    view.setUint16(22, numChannels, true);
                    /* sample rate */
                    view.setUint32(24, sampleRate, true);
                    /* byte rate (sampleRate * blockAlign) */
                    view.setUint32(28, sampleRate * blockAlign, true);
                    /* block align (channel count * bytes per sample) */
                    view.setUint16(32, blockAlign, true);
                    /* bits per sample */
                    view.setUint16(34, 8 * bytesPerSample, true);
                    /* data chunk identifier */
                    writeString(view, 36, 'data');
                    /* data chunk length */
                    view.setUint32(40, samples.length * bytesPerSample, true);

                    // Write PCM samples
                    let offset = 44;
                    for (let i = 0; i < samples.length; i++, offset += 2) {
                        let s = Math.max(-1, Math.min(1, samples[i]));
                        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
                    }

                    return new Blob([view], { type: 'audio/wav' });
                } catch (err) {
                    console.warn('Decoding audio failed, sending raw chunk as fallback:', err);
                    // As fallback, try to return original blob and hope the backend can decode it
                    return blob;
                }
            }

            async function sendAudioChunk(chunk) {
                if (!chunk || chunk.size === 0) return;

                try {
                    // Convert to WAV for best compatibility with Python speech_recognition
                    const wavBlob = await blobToWav(chunk);

                    const response = await fetch(PYTHON_API_URL, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'audio/wav'
                        },
                        body: wavBlob
                    });

                    const data = await response.json();

                    if (data.success && data.transcription) {
                        // Append new transcription to existing caption, with a space
                        let newText = data.transcription.trim();
                        if (newText.length === 0) return;
                        // Limit total length to avoid overflow
                        const existing = captionOutput.textContent === 'üîä Ouvindo...' || captionOutput.textContent.startsWith('Pressione') ? '' : captionOutput.textContent;
                        const combined = (existing + ' ' + newText).trim();
                        captionOutput.textContent = combined.length > 500 ? combined.slice(-500) : combined;
                    } else {
                        if (data.transcription && data.transcription !== "[Sil√™ncio ou √°udio inintelig√≠vel]") {
                            const newText = data.transcription.trim();
                            const existing = captionOutput.textContent === 'üîä Ouvindo...' || captionOutput.textContent.startsWith('Pressione') ? '' : captionOutput.textContent;
                            const combined = (existing + ' ' + newText).trim();
                            captionOutput.textContent = combined.length > 500 ? combined.slice(-500) : combined;
                        }
                    }
                } catch (error) {
                    console.error('Erro na comunica√ß√£o com o backend Python:', error);
                    captionOutput.textContent = 'Erro de Rede/Python. Verifique o servidor (porta 5001).';
                    stopRecording();
                }
            }
            
            // ... (Seu c√≥digo de startRecording, stopProcessing, stopRecording) ...
            function startRecording() {
                captionOutput.textContent = 'Iniciando microfone...';
                
                navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 44100,
                        sampleSize: 16,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                })
                .then(stream => {
                    audioStream = stream;
                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm; codecs=pcm' });
                    
                    mediaRecorder.ondataavailable = event => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };
                    
                    mediaRecorder.onstop = stopProcessing;

                    mediaRecorder.start(CHUNK_INTERVAL);
                    
                    isListening = true;
                    isPaused = false;
                    captionOutput.textContent = 'üîä Ouvindo...';
                    // Reset caption to start fresh for this session
                    captionOutput.textContent = 'üîä Ouvindo...';
                    pauseResumeButton.disabled = false;
                    stopButton.disabled = false;
                    startButton.disabled = true;
                    pauseResumeButton.innerHTML = '<i class="fas fa-pause"></i> PAUSAR';

                    const sendLoop = setInterval(() => {
                        if (isListening && !isPaused && audioChunks.length > 0) {
                            const audioBlob = new Blob(audioChunks, { type: 'application/octet-stream' });
                            sendAudioChunk(audioBlob);
                            audioChunks = [];
                        }
                        if (!isListening && sendLoop) clearInterval(sendLoop); 
                    }, CHUNK_INTERVAL);
                })
                .catch(error => {
                    console.error('Erro ao acessar o microfone:', error);
                    captionOutput.textContent = 'Erro: Microfone bloqueado ou inacess√≠vel.';
                    stopRecording();
                });
            }
            
            function stopProcessing() {
                isListening = false;
                startButton.disabled = false;
                pauseResumeButton.disabled = true;
                stopButton.disabled = true;
                
                if(audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }
                captionOutput.textContent = captionOutput.textContent + ' [Reconhecimento encerrado.]';
            }

            function stopRecording() {
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    mediaRecorder.stop();
                } else {
                    stopProcessing();
                }
                disableInteraction();
            }
            
            // --- MANIPULADORES DE BOT√ÉO ---

            // A linha que falhava antes, agora funciona!
            startButton.addEventListener('click', () => { 
                enableInteraction(); 
                startRecording();
            });

            pauseResumeButton.addEventListener('click', () => {
                if (isListening) {
                    if (isPaused) {
                        mediaRecorder.resume(); 
                        isPaused = false;
                        pauseResumeButton.innerHTML = '<i class="fas fa-pause"></i> PAUSAR';
                        captionOutput.textContent = 'üîä Retomando a escuta...';
                    } else {
                        mediaRecorder.pause(); 
                        isPaused = true;
                        pauseResumeButton.innerHTML = '<i class="fas fa-play"></i> VOLTAR';
                        captionOutput.textContent = '‚è∏Ô∏è Pausado.';
                    }
                }
            });

            stopButton.addEventListener('click', () => {
                stopRecording(); 
            });
            
            // --- HABILITAR CONTROLES INICIAIS (Clique duplo na legenda para mostrar) ---
            captionContainer.addEventListener('dblclick', enableInteraction);

        }); // FIM do DOMContentLoaded
    </script>
</body>
</html>